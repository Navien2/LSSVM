{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Least-Squares Support Vector machine</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  Features.shape:   # of classes:\n",
      "vc2c      (310, 6)          2\n",
      "vc3c      (310, 6)          3\n",
      "wf24f     (5456, 24)        4\n",
      "wf4f      (5456, 4)         4\n",
      "wf2f      (5456, 2)         4\n",
      "pk        (195, 22)         2\n"
     ]
    }
   ],
   "source": [
    "%run -i 'load_dataset.py' # loading dataset\n",
    "%run -i 'aux_func.py'     # loading auxilary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class implementation of LS-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot, exp\n",
    "from functools import partial \n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class LSSVM:\n",
    "    'Class the implements the Least-Squares Support Vector machine.'\n",
    "    \n",
    "    def __init__(self, gamma=1, kernel='rbf', **kernel_params): \n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.x        = None\n",
    "        self.y        = None\n",
    "        self.y_labels = None\n",
    "        \n",
    "        self.alpha = None\n",
    "        self.b     = None\n",
    "        \n",
    "        self.kernel = LSSVM.get_kernel(kernel, **kernel_params) # saving kernel function\n",
    "        \n",
    "           \n",
    "    @staticmethod\n",
    "    def get_kernel(name, **params):\n",
    "        \n",
    "        def linear(x_i, x_j):                           \n",
    "            return dot(x_i, x_j.T)\n",
    "        \n",
    "        def poly(x_i, x_j, d=params.get('d',3)):        \n",
    "            return ( dot(x_i, x_j.T) + 1 )**d\n",
    "        \n",
    "        def rbf(x_i, x_j, sigma=params.get('sigma',1)):\n",
    "            if x_i.ndim==x_i.ndim and x_i.ndim==2: # both matrices\n",
    "                return exp( -cdist(x_i,x_j)**2 / sigma**2 )\n",
    "#             return exp( -( dot(x_i,x_i.T) + dot(x_j,x_j.T)- 2*dot(x_i,x_j) ) / sigma**2 )\n",
    "#             temp = x_i.T - X\n",
    "#             return exp( -dot(temp.temp) / sigma**2 )\n",
    "                \n",
    "        kernels = {'linear': linear, 'poly': poly, 'rbf': rbf}\n",
    "                \n",
    "        if kernels.get(name) is None: \n",
    "            raise KeyError(\"Kernel '{}' is not defined, try one of the list: {}.\".format(\n",
    "                name, list(kernels.keys())))\n",
    "        else: return kernels[name]\n",
    "        \n",
    "    \n",
    "    def opt_params(self, X, y_values):\n",
    "        sigma = np.multiply( y_values*y_values.T, self.kernel(X,X) )\n",
    "\n",
    "        A_cross = np.linalg.pinv(np.block([\n",
    "            [0,                      y_values.T                   ],\n",
    "            [y_values,   sigma + self.gamma**-1 * np.eye(len(y_values))]\n",
    "        ]))\n",
    "\n",
    "        B = np.array([0]+[1]*len(y_values))\n",
    "\n",
    "        solution = dot(A_cross, B)\n",
    "        b     = solution[0]\n",
    "        alpha = solution[1:]\n",
    "        \n",
    "        return (b, alpha)\n",
    "            \n",
    "    \n",
    "    def fit(self, X, Y, verboses=0):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.y_labels = np.unique(Y, axis=0)\n",
    "        \n",
    "        if len(self.y_labels)==2: # binary classification\n",
    "            # converting to -1/+1\n",
    "            y_values = np.where(\n",
    "                (Y == self.y_labels[0]).all(axis=1)\n",
    "                ,-1,+1)[:,np.newaxis] # making it a column vector\n",
    "            \n",
    "            self.b, self.alpha = self.opt_params(X, y_values)\n",
    "        \n",
    "        else: # multiclass classification\n",
    "              # ONE-VS-ALL APPROACH\n",
    "            n_classes = len(self.y_labels)\n",
    "            self.b      = np.zeros(n_classes)\n",
    "            self.alpha = np.zeros((n_classes, len(Y)))\n",
    "            for i in range(len(self.y_labels)):\n",
    "                # converting to +1 for the desired class and -1 for all other classes\n",
    "                y_values = np.where(\n",
    "                    (Y == self.y_labels[i]).all(axis=1)\n",
    "                    ,+1,-1)[:,np.newaxis] # making it a column vector\n",
    "  \n",
    "                self.b[i], self.alpha[i] = self.opt_params(X, y_values)\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        k = self.kernel(self.x, X)\n",
    "        \n",
    "        if len(self.y_labels)==2: # binary classification\n",
    "            y_values = np.where(self.y==self.y_labels[0],-1,1)\n",
    "            Y = np.sign( dot( np.multiply(self.alpha, y_values.flatten()), k ) + self.b)\n",
    "            \n",
    "            y_pred_labels = np.where(Y==-1,        self.y_labels[0],\n",
    "                                     np.where(Y==1,self.y_labels[1],Y))\n",
    "        \n",
    "        else: # multiclass classification, ONE-VS-ALL APPROACH\n",
    "            Y = np.zeros((len(self.y_labels), len(X)))\n",
    "            for i in range(len(self.y_labels)):\n",
    "                y_values = np.where((self.y == self.y_labels[i]).all(axis=1),\n",
    "                                         +1, -1)[:,np.newaxis] # making it a column vector\n",
    "                Y[i] = np.sign( dot( np.multiply(self.alpha[i], y_values.flatten()), k ) + self.b[i])\n",
    "            \n",
    "            predictions = np.argmax(Y, axis=0)\n",
    "            y_pred_labels = np.array([self.y_labels[i] for i in predictions])\n",
    "            \n",
    "        return y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vc2c\n",
      "linear kernel\n",
      "acc_test =  0.8548387096774194\n",
      "poly kernel\n",
      "acc_test =  0.8548387096774194\n",
      "rbf kernel\n",
      "acc_test =  0.8709677419354839\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "vc3c\n",
      "linear kernel\n",
      "acc_test =  0.7096774193548387\n",
      "poly kernel\n",
      "acc_test =  0.7419354838709677\n",
      "rbf kernel\n",
      "acc_test =  0.7580645161290323\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "pk\n",
      "linear kernel\n",
      "acc_test =  0.8974358974358975\n",
      "poly kernel\n",
      "acc_test =  0.9230769230769231\n",
      "rbf kernel\n",
      "acc_test =  0.9230769230769231\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "CPU times: user 1.8 s, sys: 1.32 s, total: 3.12 s\n",
      "Wall time: 412 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "small_datasets =['vc2c', 'vc3c', 'pk']\n",
    "\n",
    "for dataset_name in small_datasets:\n",
    "    print(dataset_name)\n",
    "\n",
    "    X = datasets[dataset_name]['features'].values\n",
    "    Y = datasets[dataset_name]['labels'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)  # Train/Test split = 80%/20%\n",
    "    X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, scaleType='min-max') # scaling features\n",
    "    \n",
    "    print('linear kernel')\n",
    "    lssvm = LSSVM(gamma=1, kernel='linear')\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ', accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm))))\n",
    "    \n",
    "    print('poly kernel')\n",
    "    lssvm = LSSVM(gamma=1, kernel='poly', d=2)\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ',accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm))))\n",
    "    \n",
    "    print('rbf kernel')\n",
    "    lssvm = LSSVM(gamma=1, kernel='rbf', sigma=1)\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ',accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm))))\n",
    "    \n",
    "    print('\\n','#'*100,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
